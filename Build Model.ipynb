{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. linear model is overfitted\n",
    "2. need to adjust volume data during vacation\n",
    "3. blend linear prediction and last two hours prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create features as hour_min for four hours and three minute slots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. combi_in_1_t: festival above normal\n",
    "2. combi_in_2_t: festival below normal\n",
    "3. combi_in_3_t: festival equals normal\n",
    "4. combi_out_1_t: festival below normal\n",
    "5. combi_out_3_t: festival below normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1907,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import datetime\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1908,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1909,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MAPE(preds, outputs):\n",
    "    preds = np.array(preds)\n",
    "    outputs = np.array(outputs)\n",
    "    return np.average(np.abs(outputs - preds) / outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1910,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sma_week_vwt = pd.read_csv('train_vwt.csv')\n",
    "\n",
    "sma_week_vwt['window_time_formatted'] = sma_week_vwt['window_time_formatted'].apply(\n",
    "            lambda t : datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "sma_week_vwt['date'] = sma_week_vwt['window_time_formatted'].apply(lambda t : t.date())\n",
    "\n",
    "# sma_week_vwt_nfes = sma_week_vwt.copy()\n",
    "sma_week_vwt_nfes = sma_week_vwt[sma_week_vwt['is_festival'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1911,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combi_in = sma_week_vwt_nfes[sma_week_vwt_nfes['direction'] == 0]\n",
    "combi_out = sma_week_vwt_nfes[sma_week_vwt_nfes['direction'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1912,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "combi_in['day_hour'] = (combi_in['month'].astype(int).astype(str) + \n",
    "    combi_in['day'].astype(int).astype(str) + combi_in['hour'].astype(int).astype(str)).astype(int)\n",
    "combi_out['day_hour'] = (combi_out['month'].astype(int).astype(str) +\n",
    "    combi_out['day'].astype(int).astype(str) + combi_out['hour'].astype(int).astype(str)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1913,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "combi_in['month_day'] = (combi_in['month'].astype(int).astype(str) + combi_in['day'].astype(int).astype(str)).astype(int)\n",
    "combi_out['month_day'] = (combi_out['month'].astype(int).astype(str) +combi_out['day'].astype(int).astype(str)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1914,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_features = ['is_festival', 'is_working_day', 'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', \n",
    "              'weekday_4', 'weekday_5', 'weekday_6', 'hour_8', 'hour_9', 'hour_17', 'hour_18',\n",
    "               'rounded_min_0', 'rounded_min_20', 'rounded_min_40', \n",
    "              'wind_direction_0.0', 'wind_direction_15.0', 'wind_direction_30.0', 'wind_direction_45.0', 'wind_direction_60.0', \n",
    "              'wind_direction_75.0', 'wind_direction_90.0', 'wind_direction_105.0', 'wind_direction_120.0', \n",
    "              'wind_direction_135.0', 'wind_direction_150.0', 'wind_direction_165.0', 'wind_direction_180.0', \n",
    "              'wind_direction_195.0', 'wind_direction_210.0', 'wind_direction_225.0', 'wind_direction_240.0', \n",
    "              'wind_direction_255.0', 'wind_direction_270.0', 'wind_direction_285.0', 'wind_direction_300.0', \n",
    "              'wind_direction_315.0', 'wind_direction_330.0', 'wind_direction_345.0', 'wind_direction_360.0', \n",
    "              'wind_speed_0.0', 'wind_speed_1.0', 'wind_speed_2.0', 'wind_speed_3.0', 'wind_speed_4.0', 'wind_speed_5.0', \n",
    "              'wind_speed_6.0', 'wind_speed_7.0', 'temperature_14.0', 'temperature_16.0', 'temperature_18.0', \n",
    "              'temperature_20.0', 'temperature_22.0', 'temperature_24.0', 'temperature_26.0', 'temperature_28.0', \n",
    "              'temperature_30.0', 'temperature_32.0', 'rel_humidity_40.0', 'rel_humidity_50.0', 'rel_humidity_60.0', \n",
    "              'rel_humidity_70.0', 'rel_humidity_80.0', 'rel_humidity_90.0', 'precipitation_-0.0', 'precipitation_1.0', \n",
    "              'precipitation_2.0', 'precipitation_3.0', 'precipitation_4.0', 'precipitation_5.0', \n",
    "             ]\n",
    "\n",
    "in_features += ['his_ave', 'traj_count', 'travel_time', \n",
    "              'count_ft_1', 'count_ft_2', 'count_ft_3', 'count_ft_4', 'count_ft_5', 'count_ft_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1915,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "out_features = copy.deepcopy(in_features)\n",
    "\n",
    "# out_features.remove('traj_count')\n",
    "# out_features.remove('travel_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1916,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for f in in_features:\n",
    "    if f not in combi_in:\n",
    "        combi_in[f] = np.array([0] * len(combi_in))\n",
    "        \n",
    "for f in out_features:\n",
    "    if f not in combi_out:\n",
    "        combi_out[f] = np.array([0] * len(combi_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1917,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combi_in = combi_in[combi_in['hour'].isin([8, 9, 17, 18])]\n",
    "combi_out = combi_out[combi_out['hour'].isin([8, 9, 17, 18])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1918,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combi_in_1 = combi_in[combi_in['tollgate_id'] == 1]\n",
    "combi_in_2 = combi_in[combi_in['tollgate_id'] == 2]\n",
    "combi_in_3 = combi_in[combi_in['tollgate_id'] == 3]\n",
    "combi_out_1 = combi_out[combi_out['tollgate_id'] == 1]\n",
    "combi_out_3 = combi_out[combi_out['tollgate_id'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1919,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "data_sets = [combi_in_1, combi_in_2, combi_in_3, combi_out_1, combi_out_3]\n",
    "\n",
    "data_names = [\"entry1\", 'entry2', 'entry3', 'exit1', 'exit3']\n",
    "\n",
    "feature_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    if i <= 2:\n",
    "        feature_list.append(in_features)\n",
    "    else:\n",
    "        feature_list.append(out_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1921,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def fit_model_DT(X_train_valid, Y_train_valid):\n",
    "    \n",
    "    mapes = []\n",
    "    regs = []\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        depth = 1+i\n",
    "        mape_list = []\n",
    "        \n",
    "        for t_index, v_index in kf.split(X_train_valid):\n",
    "\n",
    "            train_X = X_train_valid.loc[t_index]\n",
    "            valid_X = X_train_valid.loc[v_index]\n",
    "            train_Y = Y_train_valid.loc[t_index]\n",
    "            valid_Y = Y_train_valid.loc[v_index]\n",
    "\n",
    "            reg = DecisionTreeRegressor(max_depth=depth)\n",
    "            reg.fit(train_X, train_Y)\n",
    "            pred = reg.predict(valid_X)\n",
    "            mape_list.append(MAPE(pred, valid_Y))\n",
    "            \n",
    "        mapes.append(np.average(mape_list))\n",
    "    \n",
    "    index = np.array(mapes).argmin()\n",
    "    best_depth = index + 1\n",
    "    mape = np.average(mape_list)\n",
    "    reg = DecisionTreeRegressor(max_depth=best_depth)\n",
    "    reg.fit(X_train_valid,Y_train_valid)\n",
    "    \n",
    "    return (best_depth, mape, reg)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1922,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def fit_model_LinearReg(X_train_valid, Y_train_valid, minalpha=3, maxalpha=20):\n",
    "    \n",
    "    preds = []\n",
    "    mapes = []\n",
    "    regs = []\n",
    "\n",
    "    alphas = np.arange(minalpha, maxalpha, 0.1)\n",
    "    \n",
    "    for a in alphas:\n",
    "        \n",
    "        kf = KFold(n_splits=5)\n",
    "        mape_list = []\n",
    "        for t_index, v_index in kf.split(X_train_valid):\n",
    "            \n",
    "            train_X = X_train_valid.loc[t_index]\n",
    "            valid_X = X_train_valid.loc[v_index]\n",
    "            train_Y = Y_train_valid.loc[t_index]\n",
    "            valid_Y = Y_train_valid.loc[v_index]\n",
    "            \n",
    "            reg = linear_model.Ridge(alpha=a)\n",
    "            reg.fit(train_X, train_Y)\n",
    "            pred = reg.predict(valid_X)\n",
    "            mape = MAPE(pred, valid_Y)\n",
    "            mape_list.append(mape)\n",
    "        mapes.append(np.average(mape_list))\n",
    "        \n",
    "    index = np.array(mapes).argmin()\n",
    "    alpha = alphas[index]\n",
    "    mape = mapes[index]\n",
    "    reg = linear_model.Ridge(alpha=alpha)\n",
    "    reg.fit(X_train_valid, Y_train_valid)\n",
    "    \n",
    "    return (alpha, mape, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1923,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def fit_model_GB(X_train_valid, Y_train_valid):\n",
    "    \n",
    "    mapes = []\n",
    "    regs = []\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        depth = 1+i\n",
    "        mape_list = []\n",
    "        \n",
    "        for t_index, v_index in kf.split(X_train_valid):\n",
    "\n",
    "            train_X = X_train_valid.loc[t_index]\n",
    "            valid_X = X_train_valid.loc[v_index]\n",
    "            train_Y = Y_train_valid.loc[t_index]\n",
    "            valid_Y = Y_train_valid.loc[v_index]\n",
    "\n",
    "            reg = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1, max_depth=depth, random_state=seed, loss='ls')\n",
    "            reg.fit(train_X, train_Y)\n",
    "            pred = reg.predict(valid_X)\n",
    "            mape_list.append(MAPE(pred, valid_Y))\n",
    "            \n",
    "        mapes.append(np.average(mape_list))\n",
    "    \n",
    "    index = np.array(mapes).argmin()\n",
    "    best_depth = index + 1\n",
    "    mape = np.average(mape_list)\n",
    "    reg = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=best_depth, random_state=0, loss='ls')\n",
    "    reg.fit(X_train_valid,Y_train_valid)\n",
    "    \n",
    "    return (best_depth, mape, reg)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1983,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?xgb.XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1984,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def fit_model_XGB(X_train_valid, Y_train_valid):\n",
    "    \n",
    "    mapes = []\n",
    "    regs = []\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        depth = 1+i\n",
    "        mape_list = []\n",
    "        \n",
    "        for t_index, v_index in kf.split(X_train_valid):\n",
    "\n",
    "            train_X = X_train_valid.loc[t_index]\n",
    "            valid_X = X_train_valid.loc[v_index]\n",
    "            train_Y = Y_train_valid.loc[t_index]\n",
    "            valid_Y = Y_train_valid.loc[v_index]\n",
    "\n",
    "            reg = xgb.XGBRegressor(max_depth=depth, n_estimators=1000)\n",
    "#             reg = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1, max_depth=depth, random_state=seed, loss='ls')\n",
    "            reg.fit(train_X, train_Y)\n",
    "            pred = reg.predict(valid_X)\n",
    "            mape_list.append(MAPE(pred, valid_Y))\n",
    "            \n",
    "        mapes.append(np.average(mape_list))\n",
    "    \n",
    "    index = np.array(mapes).argmin()\n",
    "    best_depth = index + 1\n",
    "    mape = np.average(mape_list)\n",
    "    reg = xgb.XGBRegressor(max_depth=best_depth, n_estimators=1000)\n",
    "#     reg = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=best_depth, random_state=0, loss='ls')\n",
    "    reg.fit(X_train_valid,Y_train_valid)\n",
    "    \n",
    "    return (best_depth, mape, reg)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1980,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_XGB_models(Xs_train_valid, Ys_train_valid, verbose=True):\n",
    "\n",
    "    mapes_validation = []\n",
    "    XGB_models = []\n",
    "    total_val_mapes = []\n",
    "    total_test_mapes = []\n",
    "\n",
    "    for i in range(5):\n",
    "        (max_depth, mape_valid, reg) = fit_model_XGB(Xs_train_valid[i], Ys_train_valid[i])\n",
    "\n",
    "        mapes_validation.append(mape_valid)\n",
    "        GB_models.append(reg)\n",
    "\n",
    "        X_test = Xs_test[i]\n",
    "        Y_test = Ys_test[i]\n",
    "        pred = reg.predict(X_test)\n",
    "        mape_test = MAPE(pred, Y_test)\n",
    "\n",
    "        total_val_mapes.append(mape_valid)\n",
    "        total_test_mapes.append(mape_test)\n",
    "\n",
    "        if verbose:\n",
    "            print 'max_depth:', max_depth, 'mape_valid:', mape_valid, 'mape_test:', mape_test\n",
    "\n",
    "    print 'Validation mape:', np.average(total_val_mapes)\n",
    "    print 'Test mape:', np.average(total_test_mapes)\n",
    "    \n",
    "    return XGB_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1924,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_GB_models(Xs_train_valid, Ys_train_valid, verbose=True):\n",
    "\n",
    "    mapes_validation = []\n",
    "    GB_models = []\n",
    "    total_val_mapes = []\n",
    "    total_test_mapes = []\n",
    "\n",
    "    for i in range(5):\n",
    "        (max_depth, mape_valid, reg) = fit_model_GB(Xs_train_valid[i], Ys_train_valid[i])\n",
    "\n",
    "        alphas.append(alpha)\n",
    "        mapes_validation.append(mape_valid)\n",
    "        GB_models.append(reg)\n",
    "\n",
    "        X_test = Xs_test[i]\n",
    "        Y_test = Ys_test[i]\n",
    "        pred = reg.predict(X_test)\n",
    "        mape_test = MAPE(pred, Y_test)\n",
    "\n",
    "        total_val_mapes.append(mape_valid)\n",
    "        total_test_mapes.append(mape_test)\n",
    "\n",
    "        if verbose:\n",
    "            print 'max_depth:', max_depth, 'mape_valid:', mape_valid, 'mape_test:', mape_test\n",
    "\n",
    "    print 'Validation mape:', np.average(total_val_mapes)\n",
    "    print 'Test mape:', np.average(total_test_mapes)\n",
    "    \n",
    "    return GB_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1925,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_LR_models(Xs_train_valid, Ys_train_valid, verbose=True, minalpha=3, maxalpha=20):\n",
    "    \n",
    "    mapes_validation = []\n",
    "    LR_models = []\n",
    "    total_val_mapes = []\n",
    "    total_test_mapes = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        (alpha, mape_valid, reg) = fit_model_LinearReg(Xs_train_valid[i], Ys_train_valid[i], minalpha, maxalpha)\n",
    "\n",
    "        alphas.append(alpha)\n",
    "        mapes_validation.append(mape_valid)\n",
    "        LR_models.append(reg)\n",
    "\n",
    "        X_test = Xs_test[i]\n",
    "        Y_test = Ys_test[i]\n",
    "        pred = reg.predict(X_test)\n",
    "        mape_test = MAPE(pred, Y_test)\n",
    "\n",
    "        total_val_mapes.append(mape_valid)\n",
    "        total_test_mapes.append(mape_test)\n",
    "\n",
    "        if verbose:\n",
    "            print 'alpha:', alpha, 'mape_valid:', mape_valid, 'mape_test:', mape_test\n",
    "            \n",
    "    print 'Validation mape:', np.average(total_val_mapes)\n",
    "    print 'Test mape:', np.average(total_test_mapes)\n",
    "    \n",
    "    return LR_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1926,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_DT_models(Xs_train_valid, Ys_train_valid, verbose=True):\n",
    "\n",
    "    mapes_validation = []\n",
    "    DT_models = []\n",
    "    total_val_mapes = []\n",
    "    total_test_mapes = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        \n",
    "        (max_depth, mape_valid, reg) = fit_model_DT(Xs_train_valid[i], Ys_train_valid[i])\n",
    "\n",
    "        mapes_validation.append(mape_valid)\n",
    "        DT_models.append(reg)\n",
    "\n",
    "        X_test = Xs_test[i]\n",
    "        Y_test = Ys_test[i]\n",
    "        pred = reg.predict(X_test)\n",
    "        mape_test = MAPE(pred, Y_test)\n",
    "\n",
    "        total_val_mapes.append(mape_valid)\n",
    "        total_test_mapes.append(mape_test)\n",
    "\n",
    "        if verbose:\n",
    "            print 'max_depth:', max_depth, 'mape_valid:', mape_valid, 'mape_test:', mape_test\n",
    "            \n",
    "    print 'Validation mape:', np.average(total_val_mapes)\n",
    "    print 'Test mape:', np.average(total_test_mapes)\n",
    "    \n",
    "    return DT_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1952,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_valid:  252\n",
      "test:  72\n"
     ]
    }
   ],
   "source": [
    "Xs_train_valid = []\n",
    "Ys_train_valid = []\n",
    "Xs_test = []\n",
    "Ys_test = []\n",
    "\n",
    "time_thres = datetime.date(2016, 10, 18)\n",
    "\n",
    "for i in range(5):\n",
    "    df = data_sets[i]\n",
    "    features = feature_list[i]\n",
    "    \n",
    "    train = df[df['date'] <= time_thres]\n",
    "    test = df[df['date'] > time_thres]\n",
    "    Xs_train_valid.append(train[features])\n",
    "    Ys_train_valid.append(train['count'])\n",
    "    Xs_test.append(test[features])\n",
    "    Ys_test.append(test['count'])\n",
    "print 'train_valid: ', len(Xs_train_valid[0])\n",
    "print 'test: ', len(Xs_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1953,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    Xs_train_valid[i] = Xs_train_valid[i].sample(frac=1, random_state=seed)\n",
    "    Ys_train_valid[i] = Ys_train_valid[i].sample(frac=1, random_state=seed)\n",
    "\n",
    "    Xs_train_valid[i].index = range(len(Xs_train_valid[i]))\n",
    "    Ys_train_valid[i].index = range(len(Ys_train_valid[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1957,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5.0 mape_valid: 0.168678199942 mape_test: 0.199027670816\n",
      "alpha: 5.0 mape_valid: 0.264744104762 mape_test: 0.135791991469\n",
      "alpha: 29.9 mape_valid: 0.121014189481 mape_test: 0.0905822816405\n",
      "alpha: 29.9 mape_valid: 0.104200125524 mape_test: 0.0966874367881\n",
      "alpha: 5.0 mape_valid: 0.102868137605 mape_test: 0.146280283724\n",
      "Validation mape: 0.152300951463\n",
      "Test mape: 0.133673932888\n"
     ]
    }
   ],
   "source": [
    "LR_models = train_LR_models(Xs_train_valid, Ys_train_valid, verbose=True, minalpha=5, maxalpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1971,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 4 mape_valid: 0.205458528941 mape_test: 0.217306757333\n",
      "max_depth: 2 mape_valid: 0.542002305664 mape_test: 0.231335496883\n",
      "max_depth: 4 mape_valid: 0.15733724396 mape_test: 0.129147107918\n",
      "max_depth: 3 mape_valid: 0.148483540094 mape_test: 0.128606953882\n",
      "max_depth: 4 mape_valid: 0.137911450825 mape_test: 0.174614602386\n",
      "Validation mape: 0.238238613897\n",
      "Test mape: 0.17620218368\n"
     ]
    }
   ],
   "source": [
    "DT_models = train_DT_models(Xs_train_valid, Ys_train_valid, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1988,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1 mape_valid: 0.167889671279 mape_test: 0.204254482235\n",
      "max_depth: 1 mape_valid: 0.333015930453 mape_test: 0.178493263986\n",
      "max_depth: 1 mape_valid: 0.124281847874 mape_test: 0.113636020156\n",
      "max_depth: 1 mape_valid: 0.135818989557 mape_test: 0.0997036984666\n",
      "max_depth: 1 mape_valid: 0.117059752864 mape_test: 0.142114055508\n",
      "Validation mape: 0.175613238406\n",
      "Test mape: 0.14764030407\n"
     ]
    }
   ],
   "source": [
    "GB_models = train_GB_models(Xs_train_valid, Ys_train_valid, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1989,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1 mape_valid: 0.170222740557 mape_test: 0.215452914295\n",
      "max_depth: 1 mape_valid: 0.344033645645 mape_test: 0.166128839794\n",
      "max_depth: 3 mape_valid: 0.118074869341 mape_test: 0.09672668825\n",
      "max_depth: 1 mape_valid: 0.134833819612 mape_test: 0.115430537584\n",
      "max_depth: 1 mape_valid: 0.114591609451 mape_test: 0.169606199361\n",
      "Validation mape: 0.176351336921\n",
      "Test mape: 0.152669035857\n"
     ]
    }
   ],
   "source": [
    "XGB_models = train_XGB_models(Xs_train_valid, Ys_train_valid, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_coef_df(reg_model, features):\n",
    "    coef_df = pd.DataFrame(data={'coef':reg_model.coef_, 'feature':features})\n",
    "    coef_df.sort('coef', ascending=False, inplace=True)\n",
    "    return coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_performance_df(reg_model, test_set, features, data_name=\"Default\"):\n",
    "    output = test_set['count']\n",
    "    pred = reg_model.predict(test_set[features])\n",
    "    perfor_df = pd.DataFrame(data={'time': test_set['window_time_formatted'], 'output': output, 'pred': pred})\n",
    "    mape = MAPE(pred, output)\n",
    "    print \"MAPE of\" + data_name\n",
    "    print mape\n",
    "    return (perfor_df, mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_performance_matric():\n",
    "    names = ['Entry 1', 'Entry 2', 'Entry 3', 'Exit 1', 'Exit 3']\n",
    "    models = [reg_in_1, reg_in_2, reg_in_3, reg_out_1, reg_out_3]\n",
    "    validation_mapes = [mape_in_1_v, mape_in_2_v, mape_in_3_v, mape_out_1_v, mape_out_3_v]\n",
    "    test_sets = [combi_in_1_test, combi_in_2_test, combi_in_3_test, combi_out_1_test, combi_out_3_test]\n",
    "    alphas = [a_in_1, a_in_2, a_in_3, a_out_1, a_out_3]\n",
    "    test_mapes = []\n",
    "    for i in range(5):\n",
    "        model = models[i]\n",
    "        test_set = test_sets[i]\n",
    "        if i <=2:\n",
    "            feature  = in_features\n",
    "        else: \n",
    "            feature = out_features\n",
    "        pred = model.predict(test_set[feature])\n",
    "        output = test_set['count']\n",
    "        test_mapes.append(MAPE(pred, output))\n",
    "    perf_matric = pd.DataFrame(data={'Data':names, 'alphas':alphas, 'validation_mape':validation_mapes, 'test_mape':test_mapes})\n",
    "    return perf_matric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1932,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_vwt = pd.read_csv('sub_vwt.csv')\n",
    "sub_combi_in = sub_vwt[old_sub_vwt['direction'] == 0]\n",
    "sub_combi_out = sub_vwt[old_sub_vwt['direction'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1933,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Fill features\n",
    "for f in in_features:\n",
    "    if f not in sub_combi_in.columns:\n",
    "        sub_combi_in[f] = np.array([0] * len(sub_combi_in))\n",
    "        \n",
    "for f in out_features:\n",
    "    if f not in sub_combi_out.columns:\n",
    "        sub_combi_out[f] = np.array([0] * len(sub_combi_out))\n",
    "\n",
    "# Split data by 'tollgate_id'\n",
    "sub_combi_in_1 = sub_combi_in[sub_combi_in['tollgate_id'] == 1]\n",
    "sub_combi_in_2 = sub_combi_in[sub_combi_in['tollgate_id'] == 2]\n",
    "sub_combi_in_3 = sub_combi_in[sub_combi_in['tollgate_id'] == 3]\n",
    "sub_combi_out_1 = sub_combi_out[sub_combi_out['tollgate_id'] == 1]\n",
    "sub_combi_out_3 = sub_combi_out[sub_combi_out['tollgate_id'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1944,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = LR_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1945,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_combis = [sub_combi_in_1, sub_combi_in_2, sub_combi_in_3, sub_combi_out_1, sub_combi_out_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1946,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model = models[i]\n",
    "    if i <= 2:\n",
    "        features = in_features\n",
    "    else:\n",
    "        features = out_features\n",
    "    sub_combis[i]['preds'] = model.predict(sub_combis[i][features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate submission tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1947,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_pred = pd.concat([sub_combi_in_1, sub_combi_in_2, sub_combi_in_3, sub_combi_out_1, sub_combi_out_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format submission table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1948,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_submission(df):        \n",
    "    \n",
    "    df['window_time_formatted'] = df['window_time_formatted'].apply(lambda t : datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S'))\n",
    "    df['begin'] = df['window_time_formatted'].apply(lambda t: t.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    df['end'] = df['window_time_formatted'].apply(lambda t : (t+datetime.timedelta(minutes=20))).apply(\n",
    "                   lambda t : t.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    left = np.array(['['] * len(df))\n",
    "    comma = np.array([','] * len(df))\n",
    "    right = np.array([')'] * len(df))\n",
    "\n",
    "    df['time_window'] = left + df['begin'] + comma + df['end'] + right\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1949,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_submission = format_submission(sub_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1950,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete not useful data\n",
    "my_submission = my_submission[['tollgate_id', 'direction', 'time_window', 'preds']]\n",
    "\n",
    "# Rename column name\n",
    "my_submission.rename(columns={'preds':'volume'}, inplace=True)\n",
    "\n",
    "# Convert data type\n",
    "# my_submission['volume'] = my_submission['volume'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1951,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjust volumn sequence\n",
    "my_submission = my_submission[['tollgate_id', 'time_window', 'direction', 'volume']]\n",
    "\n",
    "# Save data\n",
    "my_submission.to_csv(\"predictions/LR_prediction_528.csv\", index=False)\n",
    "\n",
    "# Load to check\n",
    "my_submission = pd.read_csv(\"predictions/LR_prediction_528.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GB_prediction_527 = pd.read_csv(\"predictions/GB_prediction_527.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_prediction_527 = pd.read_csv(\"predictions/LR_prediction_527.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>time_window</th>\n",
       "      <th>direction</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:00:00,2016-10-25 08:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>50.540210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:20:00,2016-10-25 08:40:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>45.203060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:40:00,2016-10-25 09:00:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>48.351741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 09:00:00,2016-10-25 09:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>53.658167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 09:20:00,2016-10-25 09:40:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>54.168306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tollgate_id                                time_window  direction  \\\n",
       "0            1  [2016-10-25 08:00:00,2016-10-25 08:20:00)          0   \n",
       "1            1  [2016-10-25 08:20:00,2016-10-25 08:40:00)          0   \n",
       "2            1  [2016-10-25 08:40:00,2016-10-25 09:00:00)          0   \n",
       "3            1  [2016-10-25 09:00:00,2016-10-25 09:20:00)          0   \n",
       "4            1  [2016-10-25 09:20:00,2016-10-25 09:40:00)          0   \n",
       "\n",
       "      volume  \n",
       "0  50.540210  \n",
       "1  45.203060  \n",
       "2  48.351741  \n",
       "3  53.658167  \n",
       "4  54.168306  "
      ]
     },
     "execution_count": 1269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_prediction_527.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>time_window</th>\n",
       "      <th>direction</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:00:00,2016-10-25 08:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>51.715947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:20:00,2016-10-25 08:40:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>46.068362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:40:00,2016-10-25 09:00:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>48.214917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 09:00:00,2016-10-25 09:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>57.494315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 09:20:00,2016-10-25 09:40:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>57.479330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tollgate_id                                time_window  direction  \\\n",
       "0            1  [2016-10-25 08:00:00,2016-10-25 08:20:00)          0   \n",
       "1            1  [2016-10-25 08:20:00,2016-10-25 08:40:00)          0   \n",
       "2            1  [2016-10-25 08:40:00,2016-10-25 09:00:00)          0   \n",
       "3            1  [2016-10-25 09:00:00,2016-10-25 09:20:00)          0   \n",
       "4            1  [2016-10-25 09:20:00,2016-10-25 09:40:00)          0   \n",
       "\n",
       "      volume  \n",
       "0  51.715947  \n",
       "1  46.068362  \n",
       "2  48.214917  \n",
       "3  57.494315  \n",
       "4  57.479330  "
      ]
     },
     "execution_count": 1266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020589479641633237"
      ]
     },
     "execution_count": 1270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE(GB_prediction_527['volume'], my_submission['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE(GB_prediction_527['volume'], LR_prediction_527['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subs = []\n",
    "in_1 = my_submission[(my_submission['tollgate_id'] == 1) & (my_submission['direction'] == 0)]\n",
    "in_2 = my_submission[(my_submission['tollgate_id'] == 2) & (my_submission['direction'] == 0)]\n",
    "in_3 = my_submission[(my_submission['tollgate_id'] == 3) & (my_submission['direction'] == 0)]\n",
    "out_1 = my_submission[(my_submission['tollgate_id'] == 1) & (my_submission['direction'] == 1)]\n",
    "out_3 = my_submission[(my_submission['tollgate_id'] == 3) & (my_submission['direction'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sma_week_vwt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vwt = sma_week_vwt.copy()\n",
    "\n",
    "vwt['window_time_formatted'] = vwt['window_time_formatted'].apply(\n",
    "            lambda t : datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "vwt['day'] = vwt['window_time_formatted'].apply(lambda t : t.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vwt = vwt[vwt['is_festival'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vwt = vwt[vwt['hour'].isin([8, 9, 17, 18])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vwt = vwt[['window_time_formatted', 'tollgate_id', 'direction', 'his_ave', 'count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_vwt = old_sub_vwt.copy()\n",
    "sub_vwt = pd.merge(sub_vwt[['window_time_formatted', 'tollgate_id', 'direction', 'his_ave']], \n",
    "                  new_volume_gp[['window_time_formatted', 'tollgate_id', 'direction', 'count']], \n",
    "                  on=['window_time_formatted', 'tollgate_id', 'direction'], suffixes=('', '_y'), how='left')\n",
    "sub_vwt['window_time_formatted'] = sub_vwt['window_time_formatted'].apply(\n",
    "            lambda t : datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S'))\n",
    "sub_vwt['day'] = sub_vwt['window_time_formatted'].apply(lambda t : t.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.191386063473\n"
     ]
    }
   ],
   "source": [
    "print MAPE(sub_vwt['his_ave'], sub_vwt['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.139660366945\n"
     ]
    }
   ],
   "source": [
    "print MAPE(vwt['his_ave'], vwt['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_sub_vwt['window_time_formatted'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xs_train_valid = []\n",
    "# Ys_train_valid = []\n",
    "# Xs_test = []\n",
    "# Ys_test = []\n",
    "# for i in range(5):\n",
    "#     df = data_sets[i]\n",
    "#     features = feature_list[i]\n",
    "    \n",
    "#     month_day = df['month_day'].unique()\n",
    "#     random.shuffle(month_day)\n",
    "#     test_size = int(0.25 * len(month_day))\n",
    "#     test_index = month_day[:test_size]\n",
    "#     train_index = month_day[test_size:]\n",
    "    \n",
    "# #     test_index = train_index.copy()\n",
    "    \n",
    "#     train = df[df['month_day'].isin(train_index)]\n",
    "#     test = df[df['month_day'].isin(test_index)]\n",
    "    \n",
    "#     Xs_train_valid.append(train[features])\n",
    "#     Ys_train_valid.append(train['count'])\n",
    "#     Xs_test.append(test[features])\n",
    "#     Ys_test.append(test['count'])\n",
    "# print 'train_valid: ', len(Xs_train_valid[0])\n",
    "# print 'test: ', len(Xs_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1901,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "his_pred = pd.read_csv('predictions/history_prediction_503.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1902,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>time_window</th>\n",
       "      <th>direction</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-18 08:00:00,2016-10-18 08:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-19 08:00:00,2016-10-19 08:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-20 08:00:00,2016-10-20 08:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-21 08:00:00,2016-10-21 08:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-22 08:00:00,2016-10-22 08:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tollgate_id                                time_window  direction  volume\n",
       "0            1  [2016-10-18 08:00:00,2016-10-18 08:20:00)          0      44\n",
       "1            1  [2016-10-19 08:00:00,2016-10-19 08:20:00)          0      44\n",
       "2            1  [2016-10-20 08:00:00,2016-10-20 08:20:00)          0      44\n",
       "3            1  [2016-10-21 08:00:00,2016-10-21 08:20:00)          0      44\n",
       "4            1  [2016-10-22 08:00:00,2016-10-22 08:20:00)          0      44"
      ]
     },
     "execution_count": 1902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1904,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1905,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection_id</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>starting_time</th>\n",
       "      <th>travel_seq</th>\n",
       "      <th>travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>1032458</td>\n",
       "      <td>2016-10-18 00:02:32</td>\n",
       "      <td>105#2016-10-18 00:02:32#8.51;100#2016-10-18 00...</td>\n",
       "      <td>47.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1008361</td>\n",
       "      <td>2016-10-18 00:06:19</td>\n",
       "      <td>115#2016-10-18 00:06:19#8.45;102#2016-10-18 00...</td>\n",
       "      <td>144.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>1030608</td>\n",
       "      <td>2016-10-18 00:07:11</td>\n",
       "      <td>105#2016-10-18 00:07:11#6.00;100#2016-10-18 00...</td>\n",
       "      <td>81.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1045369</td>\n",
       "      <td>2016-10-18 00:14:07</td>\n",
       "      <td>110#2016-10-18 00:14:07#8.74;123#2016-10-18 00...</td>\n",
       "      <td>32.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>1028919</td>\n",
       "      <td>2016-10-18 00:14:21</td>\n",
       "      <td>110#2016-10-18 00:14:21#7.84;123#2016-10-18 00...</td>\n",
       "      <td>76.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intersection_id  tollgate_id  vehicle_id        starting_time  \\\n",
       "0               B            3     1032458  2016-10-18 00:02:32   \n",
       "1               C            1     1008361  2016-10-18 00:06:19   \n",
       "2               B            3     1030608  2016-10-18 00:07:11   \n",
       "3               A            2     1045369  2016-10-18 00:14:07   \n",
       "4               A            3     1028919  2016-10-18 00:14:21   \n",
       "\n",
       "                                          travel_seq  travel_time  \n",
       "0  105#2016-10-18 00:02:32#8.51;100#2016-10-18 00...        47.55  \n",
       "1  115#2016-10-18 00:06:19#8.45;102#2016-10-18 00...       144.57  \n",
       "2  105#2016-10-18 00:07:11#6.00;100#2016-10-18 00...        81.84  \n",
       "3  110#2016-10-18 00:14:07#8.74;123#2016-10-18 00...        32.69  \n",
       "4  110#2016-10-18 00:14:21#7.84;123#2016-10-18 00...        76.52  "
      ]
     },
     "execution_count": 1905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
