{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. linear model is overfitted\n",
    "2. need to adjust volume data during vacation\n",
    "3. blend linear prediction and last two hours prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create features as hour_min for four hours and three minute slots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. combi_in_1_t: festival above normal\n",
    "2. combi_in_2_t: festival below normal\n",
    "3. combi_in_3_t: festival equals normal\n",
    "4. combi_out_1_t: festival below normal\n",
    "5. combi_out_3_t: festival below normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import datetime\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MAPE(preds, outputs):\n",
    "    preds = np.array(preds)\n",
    "    outputs = np.array(outputs)\n",
    "    return np.average(np.abs(outputs - preds) / outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1529,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1585,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sma_week_vwt = pd.read_csv('train_vwt.csv')\n",
    "\n",
    "sma_week_vwt['window_time_formatted'] = sma_week_vwt['window_time_formatted'].apply(\n",
    "            lambda t : datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "sma_week_vwt['date'] = sma_week_vwt['window_time_formatted'].apply(lambda t : t.date())\n",
    "\n",
    "sma_week_vwt_nfes = sma_week_vwt.copy()\n",
    "# sma_week_vwt_nfes = sma_week_vwt[sma_week_vwt['is_festival'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1588,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combi_in = sma_week_vwt_nfes[sma_week_vwt_nfes['direction'] == 0]\n",
    "combi_out = sma_week_vwt_nfes[sma_week_vwt_nfes['direction'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1589,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "combi_in['day_hour'] = (combi_in['month'].astype(int).astype(str) + \n",
    "    combi_in['day'].astype(int).astype(str) + combi_in['hour'].astype(int).astype(str)).astype(int)\n",
    "combi_out['day_hour'] = (combi_out['month'].astype(int).astype(str) +\n",
    "    combi_out['day'].astype(int).astype(str) + combi_out['hour'].astype(int).astype(str)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "combi_in['month_day'] = (combi_in['month'].astype(int).astype(str) + combi_in['day'].astype(int).astype(str)).astype(int)\n",
    "combi_out['month_day'] = (combi_out['month'].astype(int).astype(str) +combi_out['day'].astype(int).astype(str)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1591,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_features = ['is_festival', 'is_working_day', 'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', \n",
    "              'weekday_4', 'weekday_5', 'weekday_6', 'hour_8', 'hour_9', 'hour_17', 'hour_18',\n",
    "               'rounded_min_0', 'rounded_min_20', 'rounded_min_40', \n",
    "              'wind_direction_0.0', 'wind_direction_15.0', 'wind_direction_30.0', 'wind_direction_45.0', 'wind_direction_60.0', \n",
    "              'wind_direction_75.0', 'wind_direction_90.0', 'wind_direction_105.0', 'wind_direction_120.0', \n",
    "              'wind_direction_135.0', 'wind_direction_150.0', 'wind_direction_165.0', 'wind_direction_180.0', \n",
    "              'wind_direction_195.0', 'wind_direction_210.0', 'wind_direction_225.0', 'wind_direction_240.0', \n",
    "              'wind_direction_255.0', 'wind_direction_270.0', 'wind_direction_285.0', 'wind_direction_300.0', \n",
    "              'wind_direction_315.0', 'wind_direction_330.0', 'wind_direction_345.0', 'wind_direction_360.0', \n",
    "              'wind_speed_0.0', 'wind_speed_1.0', 'wind_speed_2.0', 'wind_speed_3.0', 'wind_speed_4.0', 'wind_speed_5.0', \n",
    "              'wind_speed_6.0', 'wind_speed_7.0', 'temperature_14.0', 'temperature_16.0', 'temperature_18.0', \n",
    "              'temperature_20.0', 'temperature_22.0', 'temperature_24.0', 'temperature_26.0', 'temperature_28.0', \n",
    "              'temperature_30.0', 'temperature_32.0', 'rel_humidity_40.0', 'rel_humidity_50.0', 'rel_humidity_60.0', \n",
    "              'rel_humidity_70.0', 'rel_humidity_80.0', 'rel_humidity_90.0', 'precipitation_-0.0', 'precipitation_1.0', \n",
    "              'precipitation_2.0', 'precipitation_3.0', 'precipitation_4.0', 'precipitation_5.0', \n",
    "              'his_ave', 'traj_count', 'travel_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1592,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "out_features = copy.deepcopy(in_features)\n",
    "\n",
    "out_features.remove('traj_count')\n",
    "out_features.remove('travel_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1593,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for f in in_features:\n",
    "    if f not in combi_in:\n",
    "        combi_in[f] = np.array([0] * len(combi_in))\n",
    "        \n",
    "for f in out_features:\n",
    "    if f not in combi_out:\n",
    "        combi_out[f] = np.array([0] * len(combi_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1594,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combi_in = combi_in[combi_in['hour'].isin([8, 9, 17, 18])]\n",
    "combi_out = combi_out[combi_out['hour'].isin([8, 9, 17, 18])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1595,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combi_in_1 = combi_in[combi_in['tollgate_id'] == 1]\n",
    "combi_in_2 = combi_in[combi_in['tollgate_id'] == 2]\n",
    "combi_in_3 = combi_in[combi_in['tollgate_id'] == 3]\n",
    "combi_out_1 = combi_out[combi_out['tollgate_id'] == 1]\n",
    "combi_out_3 = combi_out[combi_out['tollgate_id'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1596,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "data_sets = [combi_in_1, combi_in_2, combi_in_3, combi_out_1, combi_out_3]\n",
    "\n",
    "data_names = [\"entry1\", 'entry2', 'entry3', 'exit1', 'exit3']\n",
    "\n",
    "feature_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    if i <= 2:\n",
    "        feature_list.append(in_features)\n",
    "    else:\n",
    "        feature_list.append(out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1597,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2016, 9, 19), datetime.date(2016, 9, 20),\n",
       "       datetime.date(2016, 9, 21), datetime.date(2016, 9, 22),\n",
       "       datetime.date(2016, 9, 23), datetime.date(2016, 9, 24),\n",
       "       datetime.date(2016, 9, 25), datetime.date(2016, 9, 26),\n",
       "       datetime.date(2016, 9, 27), datetime.date(2016, 9, 28),\n",
       "       datetime.date(2016, 9, 29), datetime.date(2016, 9, 30),\n",
       "       datetime.date(2016, 10, 1), datetime.date(2016, 10, 2),\n",
       "       datetime.date(2016, 10, 3), datetime.date(2016, 10, 4),\n",
       "       datetime.date(2016, 10, 5), datetime.date(2016, 10, 6),\n",
       "       datetime.date(2016, 10, 7), datetime.date(2016, 10, 8),\n",
       "       datetime.date(2016, 10, 9), datetime.date(2016, 10, 10),\n",
       "       datetime.date(2016, 10, 11), datetime.date(2016, 10, 12),\n",
       "       datetime.date(2016, 10, 13), datetime.date(2016, 10, 14),\n",
       "       datetime.date(2016, 10, 15), datetime.date(2016, 10, 16),\n",
       "       datetime.date(2016, 10, 17), datetime.date(2016, 10, 18),\n",
       "       datetime.date(2016, 10, 19), datetime.date(2016, 10, 20),\n",
       "       datetime.date(2016, 10, 21), datetime.date(2016, 10, 22),\n",
       "       datetime.date(2016, 10, 23), datetime.date(2016, 10, 24)], dtype=object)"
      ]
     },
     "execution_count": 1597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi_in['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1598,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "9\n",
      "27\n",
      "9\n",
      "27\n",
      "9\n",
      "27\n",
      "9\n",
      "27\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "Xs_train_valid = []\n",
    "Ys_train_valid = []\n",
    "Xs_test = []\n",
    "Ys_test = []\n",
    "for i in range(5):\n",
    "    df = data_sets[i]\n",
    "    features = feature_list[i]\n",
    "    \n",
    "    month_day = df['month_day'].unique()\n",
    "    random.shuffle(month_day)\n",
    "    test_size = int(0.25 * len(month_day))\n",
    "    test_index = month_day[:test_size]\n",
    "    train_index = month_day[test_size:]\n",
    "    \n",
    "#     test_index = train_index.copy()\n",
    "    \n",
    "    print len(train_index)\n",
    "    print len(test_index)\n",
    "    train = df[df['month_day'].isin(train_index)]\n",
    "    test = df[df['month_day'].isin(test_index)]\n",
    "    \n",
    "    Xs_train_valid.append(train[features])\n",
    "    Ys_train_valid.append(train['count'])\n",
    "    Xs_test.append(test[features])\n",
    "    Ys_test.append(test['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1600,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def fit_model_DT(X_train_valid, Y_train_valid):\n",
    "    \n",
    "    mapes = []\n",
    "    regs = []\n",
    "    \n",
    "    seed = randint(0, 50)\n",
    "    X_train_valid = X_train_valid.sample(frac=1, random_state=seed)\n",
    "    Y_train_valid = Y_train_valid.sample(frac=1, random_state=seed)\n",
    "    \n",
    "    X_train_valid.index = range(len(X_train_valid))\n",
    "    Y_train_valid.index = range(len(Y_train_valid))\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        depth = 1+i\n",
    "        mape_list = []\n",
    "        \n",
    "        for t_index, v_index in kf.split(X_train_valid):\n",
    "\n",
    "            train_X = X_train_valid.loc[t_index]\n",
    "            valid_X = X_train_valid.loc[v_index]\n",
    "            train_Y = Y_train_valid.loc[t_index]\n",
    "            valid_Y = Y_train_valid.loc[v_index]\n",
    "\n",
    "            reg = DecisionTreeRegressor(max_depth=depth)\n",
    "            reg.fit(train_X, train_Y)\n",
    "            pred = reg.predict(valid_X)\n",
    "            mape_list.append(MAPE(pred, valid_Y))\n",
    "            \n",
    "        mapes.append(np.average(mape_list))\n",
    "    \n",
    "    index = np.array(mapes).argmin()\n",
    "    best_depth = index + 1\n",
    "    mape = np.average(mape_list)\n",
    "    reg = DecisionTreeRegressor(max_depth=best_depth)\n",
    "    reg.fit(X_train_valid,Y_train_valid)\n",
    "    \n",
    "    return (best_depth, mape, reg)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1601,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def fit_model_LinearReg(X_train_valid, Y_train_valid, minalpha=3, maxalpha=20):\n",
    "    \n",
    "    preds = []\n",
    "    mapes = []\n",
    "    regs = []\n",
    "    \n",
    "    seed = randint(0, 50)\n",
    "    X_train_valid = X_train_valid.sample(frac=1, random_state=seed)\n",
    "    Y_train_valid = Y_train_valid.sample(frac=1, random_state=seed)\n",
    "    \n",
    "    X_train_valid.index = range(len(X_train_valid))\n",
    "    Y_train_valid.index = range(len(Y_train_valid))\n",
    "\n",
    "    alphas = np.arange(minalpha, maxalpha, 0.1)\n",
    "    \n",
    "    for a in alphas:\n",
    "        \n",
    "        kf = KFold(n_splits=5)\n",
    "        mape_list = []\n",
    "        for t_index, v_index in kf.split(X_train_valid):\n",
    "            \n",
    "            train_X = X_train_valid.loc[t_index]\n",
    "            valid_X = X_train_valid.loc[v_index]\n",
    "            train_Y = Y_train_valid.loc[t_index]\n",
    "            valid_Y = Y_train_valid.loc[v_index]\n",
    "            \n",
    "            reg = linear_model.Ridge(alpha=a)\n",
    "            reg.fit(train_X, train_Y)\n",
    "            pred = reg.predict(valid_X)\n",
    "            mape = MAPE(pred, valid_Y)\n",
    "            mape_list.append(mape)\n",
    "        mapes.append(np.average(mape_list))\n",
    "        \n",
    "    index = np.array(mapes).argmin()\n",
    "    alpha = alphas[index]\n",
    "    mape = mapes[index]\n",
    "    reg = linear_model.Ridge(alpha=alpha)\n",
    "    reg.fit(X_train_valid, Y_train_valid)\n",
    "    \n",
    "    return (alpha, mape, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1602,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1603,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def fit_model_GB(X_train_valid, Y_train_valid):\n",
    "    \n",
    "    mapes = []\n",
    "    regs = []\n",
    "    \n",
    "    seed = randint(0, 50)\n",
    "    \n",
    "    X_train_valid = X_train_valid.sample(frac=1, random_state=seed)\n",
    "    Y_train_valid = Y_train_valid.sample(frac=1, random_state=seed)\n",
    "    \n",
    "    X_train_valid.index = range(len(X_train_valid))\n",
    "    Y_train_valid.index = range(len(Y_train_valid))\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        depth = 1+i\n",
    "        mape_list = []\n",
    "        \n",
    "        for t_index, v_index in kf.split(X_train_valid):\n",
    "\n",
    "            train_X = X_train_valid.loc[t_index]\n",
    "            valid_X = X_train_valid.loc[v_index]\n",
    "            train_Y = Y_train_valid.loc[t_index]\n",
    "            valid_Y = Y_train_valid.loc[v_index]\n",
    "\n",
    "            reg = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1, max_depth=depth, random_state=seed, loss='ls')\n",
    "            reg.fit(train_X, train_Y)\n",
    "            pred = reg.predict(valid_X)\n",
    "            mape_list.append(MAPE(pred, valid_Y))\n",
    "            \n",
    "        mapes.append(np.average(mape_list))\n",
    "    \n",
    "    index = np.array(mapes).argmin()\n",
    "    best_depth = index + 1\n",
    "    mape = np.average(mape_list)\n",
    "    reg = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=best_depth, random_state=0, loss='ls')\n",
    "    reg.fit(X_train_valid,Y_train_valid)\n",
    "    \n",
    "    return (best_depth, mape, reg)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1604,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_GB_models(Xs_train_valid, Ys_train_valid, verbose=True):\n",
    "\n",
    "#     alphas = []\n",
    "    mapes_validation = []\n",
    "    GB_models = []\n",
    "    total_val_mapes = []\n",
    "    total_test_mapes = []\n",
    "\n",
    "    for i in range(5):\n",
    "        (max_depth, mape_valid, reg) = fit_model_GB(Xs_train_valid[i], Ys_train_valid[i])\n",
    "\n",
    "        alphas.append(alpha)\n",
    "        mapes_validation.append(mape_valid)\n",
    "        GB_models.append(reg)\n",
    "\n",
    "        X_test = Xs_test[i]\n",
    "        Y_test = Ys_test[i]\n",
    "        pred = reg.predict(X_test)\n",
    "        mape_test = MAPE(pred, Y_test)\n",
    "\n",
    "        total_val_mapes.append(mape_valid)\n",
    "        total_test_mapes.append(mape_test)\n",
    "\n",
    "        if verbose:\n",
    "            print 'max_depth:', max_depth, 'mape_valid:', mape_valid, 'mape_test:', mape_test\n",
    "\n",
    "    print 'Validation mape:', np.average(total_val_mapes)\n",
    "    print 'Test mape:', np.average(total_test_mapes)\n",
    "    \n",
    "    return GB_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1605,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_LR_models(Xs_train_valid, Ys_train_valid, verbose=True, minalpha=3, maxalpha=20):\n",
    "    \n",
    "    alphas = []\n",
    "    mapes_validation = []\n",
    "    LR_models = []\n",
    "    total_val_mapes = []\n",
    "    total_test_mapes = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        (alpha, mape_valid, reg) = fit_model_LinearReg(Xs_train_valid[i], Ys_train_valid[i], minalpha, maxalpha)\n",
    "\n",
    "        alphas.append(alpha)\n",
    "        mapes_validation.append(mape_valid)\n",
    "        LR_models.append(reg)\n",
    "\n",
    "        X_test = Xs_test[i]\n",
    "        Y_test = Ys_test[i]\n",
    "        pred = reg.predict(X_test)\n",
    "        mape_test = MAPE(pred, Y_test)\n",
    "\n",
    "        total_val_mapes.append(mape_valid)\n",
    "        total_test_mapes.append(mape_test)\n",
    "\n",
    "        if verbose:\n",
    "            print 'alpha:', alpha, 'mape_valid:', mape_valid, 'mape_test:', mape_test\n",
    "            \n",
    "    print 'Validation mape:', np.average(total_val_mapes)\n",
    "    print 'Test mape:', np.average(total_test_mapes)\n",
    "    \n",
    "    return LR_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1606,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_DT_models(Xs_train_valid, Ys_train_valid, verbose=True):\n",
    "\n",
    "#     alphas = []\n",
    "    mapes_validation = []\n",
    "    DT_models = []\n",
    "    total_val_mapes = []\n",
    "    total_test_mapes = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        (max_depth, mape_valid, reg) = fit_model_DT(Xs_train_valid[i], Ys_train_valid[i])\n",
    "\n",
    "#         alphas.append(alpha)\n",
    "        mapes_validation.append(mape_valid)\n",
    "        DT_models.append(reg)\n",
    "\n",
    "        X_test = Xs_test[i]\n",
    "        Y_test = Ys_test[i]\n",
    "        pred = reg.predict(X_test)\n",
    "        mape_test = MAPE(pred, Y_test)\n",
    "\n",
    "        total_val_mapes.append(mape_valid)\n",
    "        total_test_mapes.append(mape_test)\n",
    "\n",
    "        if verbose:\n",
    "            print 'max_depth:', max_depth, 'mape_valid:', mape_valid, 'mape_test:', mape_test\n",
    "            \n",
    "    print 'Validation mape:', np.average(total_val_mapes)\n",
    "    print 'Test mape:', np.average(total_test_mapes)\n",
    "    \n",
    "    return DT_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1607,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5.0 mape_valid: 0.248819988118 mape_test: 0.433887594835\n",
      "alpha: 5.0 mape_valid: 0.52984528638 mape_test: 0.661340645846\n",
      "alpha: 7.1 mape_valid: 0.145506876466 mape_test: 0.102312775189\n",
      "alpha: 5.0 mape_valid: 0.312120023306 mape_test: 0.696336983433\n",
      "alpha: 5.0 mape_valid: 0.393819602436 mape_test: 0.308550481778\n",
      "Validation mape: 0.326022355341\n",
      "Test mape: 0.440485696216\n"
     ]
    }
   ],
   "source": [
    "LR_models = train_LR_models(Xs_train_valid, Ys_train_valid, verbose=True, minalpha=5, maxalpha=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1608,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 6 mape_valid: 0.225998129162 mape_test: 0.690080293\n",
      "max_depth: 8 mape_valid: 0.364040991312 mape_test: 0.553850789107\n",
      "max_depth: 3 mape_valid: 0.204766972203 mape_test: 0.143392032624\n",
      "max_depth: 6 mape_valid: 0.195301664148 mape_test: 1.42747225654\n",
      "max_depth: 8 mape_valid: 0.239391518274 mape_test: 0.175231662803\n",
      "Validation mape: 0.24589985502\n",
      "Test mape: 0.598005406814\n"
     ]
    }
   ],
   "source": [
    "DT_models = train_DT_models(Xs_train_valid, Ys_train_valid, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 3 mape_valid: 0.215775752698 mape_test: 0.658995961214\n",
      "max_depth: 3 mape_valid: 0.389057457951 mape_test: 0.497735400268\n",
      "max_depth: 2 mape_valid: 0.153647680781 mape_test: 0.106890735083\n",
      "max_depth: 2 mape_valid: 0.194775630021 mape_test: 0.541736258038\n",
      "max_depth: 3 mape_valid: 0.235721364433 mape_test: 0.189455056674\n",
      "Validation mape: 0.237795577177\n",
      "Test mape: 0.398962682255\n"
     ]
    }
   ],
   "source": [
    "GB_models = train_GB_models(Xs_train_valid, Ys_train_valid, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_coef_df(reg_model, features):\n",
    "    coef_df = pd.DataFrame(data={'coef':reg_model.coef_, 'feature':features})\n",
    "    coef_df.sort('coef', ascending=False, inplace=True)\n",
    "    return coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_performance_df(reg_model, test_set, features, data_name=\"Default\"):\n",
    "    output = test_set['count']\n",
    "    pred = reg_model.predict(test_set[features])\n",
    "    perfor_df = pd.DataFrame(data={'time': test_set['window_time_formatted'], 'output': output, 'pred': pred})\n",
    "    mape = MAPE(pred, output)\n",
    "    print \"MAPE of\" + data_name\n",
    "    print mape\n",
    "    return (perfor_df, mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_performance_matric():\n",
    "    names = ['Entry 1', 'Entry 2', 'Entry 3', 'Exit 1', 'Exit 3']\n",
    "    models = [reg_in_1, reg_in_2, reg_in_3, reg_out_1, reg_out_3]\n",
    "    validation_mapes = [mape_in_1_v, mape_in_2_v, mape_in_3_v, mape_out_1_v, mape_out_3_v]\n",
    "    test_sets = [combi_in_1_test, combi_in_2_test, combi_in_3_test, combi_out_1_test, combi_out_3_test]\n",
    "    alphas = [a_in_1, a_in_2, a_in_3, a_out_1, a_out_3]\n",
    "    test_mapes = []\n",
    "    for i in range(5):\n",
    "        model = models[i]\n",
    "        test_set = test_sets[i]\n",
    "        if i <=2:\n",
    "            feature  = in_features\n",
    "        else: \n",
    "            feature = out_features\n",
    "        pred = model.predict(test_set[feature])\n",
    "        output = test_set['count']\n",
    "        test_mapes.append(MAPE(pred, output))\n",
    "    perf_matric = pd.DataFrame(data={'Data':names, 'alphas':alphas, 'validation_mape':validation_mapes, 'test_mape':test_mapes})\n",
    "    return perf_matric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_vwt = pd.read_csv('sub_vwt.csv')\n",
    "sub_combi_in = sub_vwt[old_sub_vwt['direction'] == 0]\n",
    "sub_combi_out = sub_vwt[old_sub_vwt['direction'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Fill features\n",
    "for f in in_features:\n",
    "    if f not in sub_combi_in.columns:\n",
    "        sub_combi_in[f] = np.array([0] * len(sub_combi_in))\n",
    "        \n",
    "for f in out_features:\n",
    "    if f not in sub_combi_out.columns:\n",
    "        sub_combi_out[f] = np.array([0] * len(sub_combi_out))\n",
    "\n",
    "# Split data by 'tollgate_id'\n",
    "sub_combi_in_1 = sub_combi_in[sub_combi_in['tollgate_id'] == 1]\n",
    "sub_combi_in_2 = sub_combi_in[sub_combi_in['tollgate_id'] == 2]\n",
    "sub_combi_in_3 = sub_combi_in[sub_combi_in['tollgate_id'] == 3]\n",
    "sub_combi_out_1 = sub_combi_out[sub_combi_out['tollgate_id'] == 1]\n",
    "sub_combi_out_3 = sub_combi_out[sub_combi_out['tollgate_id'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = GB_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_combis = [sub_combi_in_1, sub_combi_in_2, sub_combi_in_3, sub_combi_out_1, sub_combi_out_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model = models[i]\n",
    "    if i <= 2:\n",
    "        features = in_features\n",
    "    else:\n",
    "        features = out_features\n",
    "    sub_combis[i]['preds'] = model.predict(sub_combis[i][features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate submission tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_pred = pd.concat([sub_combi_in_1, sub_combi_in_2, sub_combi_in_3, sub_combi_out_1, sub_combi_out_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format submission table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_submission(df):        \n",
    "    \n",
    "    df['window_time_formatted'] = df['window_time_formatted'].apply(lambda t : datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S'))\n",
    "    df['begin'] = df['window_time_formatted'].apply(lambda t: t.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    df['end'] = df['window_time_formatted'].apply(lambda t : (t+datetime.timedelta(minutes=20))).apply(\n",
    "                   lambda t : t.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    left = np.array(['['] * len(df))\n",
    "    comma = np.array([','] * len(df))\n",
    "    right = np.array([')'] * len(df))\n",
    "\n",
    "    df['time_window'] = left + df['begin'] + comma + df['end'] + right\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_submission = format_submission(sub_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete not useful data\n",
    "my_submission = my_submission[['tollgate_id', 'direction', 'time_window', 'preds']]\n",
    "\n",
    "# Rename column name\n",
    "my_submission.rename(columns={'preds':'volume'}, inplace=True)\n",
    "\n",
    "# Convert data type\n",
    "# my_submission['volume'] = my_submission['volume'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjust volumn sequence\n",
    "my_submission = my_submission[['tollgate_id', 'time_window', 'direction', 'volume']]\n",
    "\n",
    "# Save data\n",
    "my_submission.to_csv(\"predictions/GB_prediction_527_with_traj.csv\", index=False)\n",
    "\n",
    "# Load to check\n",
    "my_submission = pd.read_csv(\"predictions/GB_prediction_527_with_traj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GB_prediction_527 = pd.read_csv(\"predictions/GB_prediction_527.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_prediction_527 = pd.read_csv(\"predictions/LR_prediction_527.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>time_window</th>\n",
       "      <th>direction</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:00:00,2016-10-25 08:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>50.540210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:20:00,2016-10-25 08:40:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>45.203060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:40:00,2016-10-25 09:00:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>48.351741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 09:00:00,2016-10-25 09:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>53.658167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 09:20:00,2016-10-25 09:40:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>54.168306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tollgate_id                                time_window  direction  \\\n",
       "0            1  [2016-10-25 08:00:00,2016-10-25 08:20:00)          0   \n",
       "1            1  [2016-10-25 08:20:00,2016-10-25 08:40:00)          0   \n",
       "2            1  [2016-10-25 08:40:00,2016-10-25 09:00:00)          0   \n",
       "3            1  [2016-10-25 09:00:00,2016-10-25 09:20:00)          0   \n",
       "4            1  [2016-10-25 09:20:00,2016-10-25 09:40:00)          0   \n",
       "\n",
       "      volume  \n",
       "0  50.540210  \n",
       "1  45.203060  \n",
       "2  48.351741  \n",
       "3  53.658167  \n",
       "4  54.168306  "
      ]
     },
     "execution_count": 1269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_prediction_527.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>time_window</th>\n",
       "      <th>direction</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:00:00,2016-10-25 08:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>51.715947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:20:00,2016-10-25 08:40:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>46.068362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 08:40:00,2016-10-25 09:00:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>48.214917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 09:00:00,2016-10-25 09:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>57.494315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-10-25 09:20:00,2016-10-25 09:40:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>57.479330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tollgate_id                                time_window  direction  \\\n",
       "0            1  [2016-10-25 08:00:00,2016-10-25 08:20:00)          0   \n",
       "1            1  [2016-10-25 08:20:00,2016-10-25 08:40:00)          0   \n",
       "2            1  [2016-10-25 08:40:00,2016-10-25 09:00:00)          0   \n",
       "3            1  [2016-10-25 09:00:00,2016-10-25 09:20:00)          0   \n",
       "4            1  [2016-10-25 09:20:00,2016-10-25 09:40:00)          0   \n",
       "\n",
       "      volume  \n",
       "0  51.715947  \n",
       "1  46.068362  \n",
       "2  48.214917  \n",
       "3  57.494315  \n",
       "4  57.479330  "
      ]
     },
     "execution_count": 1266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020589479641633237"
      ]
     },
     "execution_count": 1270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE(GB_prediction_527['volume'], my_submission['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE(GB_prediction_527['volume'], LR_prediction_527['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subs = []\n",
    "in_1 = my_submission[(my_submission['tollgate_id'] == 1) & (my_submission['direction'] == 0)]\n",
    "in_2 = my_submission[(my_submission['tollgate_id'] == 2) & (my_submission['direction'] == 0)]\n",
    "in_3 = my_submission[(my_submission['tollgate_id'] == 3) & (my_submission['direction'] == 0)]\n",
    "out_1 = my_submission[(my_submission['tollgate_id'] == 1) & (my_submission['direction'] == 1)]\n",
    "out_3 = my_submission[(my_submission['tollgate_id'] == 3) & (my_submission['direction'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sma_week_vwt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vwt = sma_week_vwt.copy()\n",
    "\n",
    "vwt['window_time_formatted'] = vwt['window_time_formatted'].apply(\n",
    "            lambda t : datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "vwt['day'] = vwt['window_time_formatted'].apply(lambda t : t.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vwt = vwt[vwt['is_festival'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vwt = vwt[vwt['hour'].isin([8, 9, 17, 18])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vwt = vwt[['window_time_formatted', 'tollgate_id', 'direction', 'his_ave', 'count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_vwt = old_sub_vwt.copy()\n",
    "sub_vwt = pd.merge(sub_vwt[['window_time_formatted', 'tollgate_id', 'direction', 'his_ave']], \n",
    "                  new_volume_gp[['window_time_formatted', 'tollgate_id', 'direction', 'count']], \n",
    "                  on=['window_time_formatted', 'tollgate_id', 'direction'], suffixes=('', '_y'), how='left')\n",
    "sub_vwt['window_time_formatted'] = sub_vwt['window_time_formatted'].apply(\n",
    "            lambda t : datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S'))\n",
    "sub_vwt['day'] = sub_vwt['window_time_formatted'].apply(lambda t : t.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.191386063473\n"
     ]
    }
   ],
   "source": [
    "print MAPE(sub_vwt['his_ave'], sub_vwt['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.139660366945\n"
     ]
    }
   ],
   "source": [
    "print MAPE(vwt['his_ave'], vwt['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_sub_vwt['window_time_formatted'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
