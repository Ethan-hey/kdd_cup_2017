{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. join 'volume' and 'trajectories' by 'end_time'\n",
    "2. have two features: 'count_traj', and 'ave_travel_time'\n",
    "3. Absolutely need to clean some outliars in 'count'\n",
    "4. Should consider the delay of conjestion relects on the volume change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. shift 'trajectories' data by two hours, and then join 'vwgrouped'\n",
    "2. more than two new featuers\n",
    "3. split the 'count_traj' by 6 time slots(3 20-min window * 2 hours) and three intersection, which ends to be 18 new features\n",
    "4. split the 'average_travel_time' as well, another 18 more new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. volume data during festival needs to be adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import datetime\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links = pd.read_csv('training/links (table 3).csv')\n",
    "routes = pd.read_csv('training/routes (table 4).csv')\n",
    "trajectories = pd.read_csv('training/trajectories(table 5)_training.csv')\n",
    "volume = pd.read_csv('training/volume(table 6)_training.csv')\n",
    "weather = pd.read_csv('training/weather (table 7)_training.csv')\n",
    "\n",
    "submission = pd.read_csv('submission_sample_volume.csv')\n",
    "test_volume = pd.read_csv('testing_phase1/volume(table 6)_test1.csv')\n",
    "test_weather = pd.read_csv('testing_phase1/weather (table 7)_test1.csv')\n",
    "\n",
    "test_trajectories = pd.read_csv('testing_phase1/trajectories(table 5)_test1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>direction</th>\n",
       "      <th>vehicle_model</th>\n",
       "      <th>has_etc</th>\n",
       "      <th>vehicle_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-19 23:09:25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-19 23:11:53</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-19 23:13:54</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-19 23:17:48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-19 23:16:07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  tollgate_id  direction  vehicle_model  has_etc  \\\n",
       "0  2016-09-19 23:09:25            2          0              1        0   \n",
       "1  2016-09-19 23:11:53            2          0              1        0   \n",
       "2  2016-09-19 23:13:54            2          0              1        0   \n",
       "3  2016-09-19 23:17:48            1          0              1        1   \n",
       "4  2016-09-19 23:16:07            2          0              1        0   \n",
       "\n",
       "   vehicle_type  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?datetime.datetime.strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_converter(volume, weather):\n",
    "    \n",
    "    # Initialize lists to store splitted information\n",
    "    date_list = []\n",
    "    month_list = []\n",
    "    day_list = []\n",
    "    hour_list = []\n",
    "    minute_list = []\n",
    "    rounded_min_list = []\n",
    "    rounded_hour_list = []\n",
    "\n",
    "    # Splits the 'time' information into month, day, hour and minute\n",
    "    def date_spliter(date):\n",
    "        \n",
    "        parts = date.split(\" \")\n",
    "        day_part = parts[0]\n",
    "        clock_part = parts[1]\n",
    "\n",
    "        day_parts = day_part.split(\"-\")\n",
    "        month = int(day_parts[1]) # Extract month from time\n",
    "        day = int(day_parts[2]) # Extract day from time\n",
    "\n",
    "        clock_parts = clock_part.split(\":\")\n",
    "        hour = int(clock_parts[0]) # Extract hour from time\n",
    "        minute = int(clock_parts[1]) # Extract minute from time\n",
    "\n",
    "        rounded_hour = str(hour // 3 * 3)\n",
    "        rounded_min = str(minute // 20 * 20)\n",
    "\n",
    "        date_list.append(day_part)\n",
    "        month_list.append(month)\n",
    "        day_list.append(day)\n",
    "        hour_list.append(hour)\n",
    "        minute_list.append(minute)\n",
    "        rounded_hour_list.append(rounded_hour)\n",
    "        rounded_min_list.append(rounded_min)\n",
    "\n",
    "    # Store info into lists\n",
    "    for date in volume['time']:\n",
    "        date_spliter(date)\n",
    "\n",
    "    # Add arrays into the 'volume' SFrame\n",
    "    volume['month'] = np.array(month_list)\n",
    "    volume['day'] = np.array(day_list)\n",
    "    volume['hour'] = np.array(hour_list)\n",
    "    volume['minute'] = np.array(minute_list)\n",
    "    volume['date'] = np.array(date_list)\n",
    "    volume['rounded_hour'] = np.array(rounded_hour_list)\n",
    "    volume['rounded_min'] = np.array(rounded_min_list)\n",
    "    \n",
    "    # Add an colume which combine 'date' and 'rounded_hour'\n",
    "    slash_list = np.array(['-'] * len(volume['date']))\n",
    "    volume['date_and_rounded_hour'] = volume['date'] + slash_list + volume['rounded_hour']\n",
    "    \n",
    "    slash_list = np.array(['-'] * len(weather['date']))\n",
    "    weather['date_and_rounded_hour'] = weather['date'] + slash_list + np.array([str(hour) for hour in weather['hour']])\n",
    "    \n",
    "    return (volume, weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(volume, weather) = date_converter(volume, weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean outliars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert 'wind_direction' outlier to 360\n",
    "weather.loc[weather['wind_direction'] > 360, 'wind_direction'] = 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build merged table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_merged_tables(volume, weather, join_type='inner'):\n",
    "    # Merge 'volume' and 'weather' DataFrame together\n",
    "    volume_weather = pd.merge(volume, weather, on='date_and_rounded_hour', suffixes=('', '_y'), how='left')\n",
    "\n",
    "    # Construct 'window_time' list which uses date, hour, and rounded minute\n",
    "    date_list = volume_weather['date'] + np.array(['-'] * len(volume_weather))\n",
    "    hour_list = volume_weather['hour'].astype(str) + np.array(['-'] * len(volume_weather))\n",
    "    window_time_list = date_list + hour_list + volume_weather['rounded_min'].astype(str)\n",
    "    volume_weather['window_time'] = window_time_list\n",
    "    \n",
    "    return volume_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volume_weather = build_merged_tables(volume, weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group 'volume_weather' here\n",
    "def group_vw(volume_weather):\n",
    "    \n",
    "    volume_weather = volume_weather.groupby(['window_time', 'tollgate_id', 'direction'])\n",
    "    vwgrouped = volume_weather.agg('mean').join(pd.DataFrame(volume_weather.size(), columns=['count']))\n",
    "\n",
    "    # Put index as column\n",
    "    vwgrouped['direction'] = vwgrouped.index.get_level_values('direction')\n",
    "    vwgrouped['tollgate_id'] = vwgrouped.index.get_level_values('tollgate_id')\n",
    "    vwgrouped['window_time'] = vwgrouped.index.get_level_values('window_time')\n",
    "    \n",
    "    vwgrouped['window_time_formatted'] = vwgrouped['window_time'].apply(\n",
    "        lambda t : datetime.datetime.strptime(t, '%Y-%m-%d-%H-%M'))\n",
    "    \n",
    "    return vwgrouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vwgrouped = group_vw(volume_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def re_construct_data(volume_weather):\n",
    "\n",
    "    # Create 'weekday' column in DateFrame(0 stands for Sunday; 1 stands for Monday and 2 stands for Tuesday, etc...)\n",
    "    if (9 in list(volume_weather['month'].unique())):\n",
    "        sept = volume_weather[volume_weather['month'] == 9]\n",
    "        weekday1 = ((sept['day'] + 3) % 7).values\n",
    "        octo = volume_weather[volume_weather['month'] == 10]\n",
    "        weekday2 = ((octo['day'] + 5) % 7).values\n",
    "        volume_weather['weekday'] = np.append(weekday1, weekday2)\n",
    "    else:\n",
    "        weekday2 = ((volume_weather['day'] + 5) % 7).values\n",
    "        volume_weather['weekday'] = np.array(weekday2)\n",
    "    \n",
    "    # Create 'rounded_min' column\n",
    "    volume_weather['rounded_min'] = volume_weather['minute'] // 20 * 20\n",
    "    \n",
    "    # Construct 'is_festival' column\n",
    "    volume_weather['is_festival'] = np.array([0] * len(volume_weather))\n",
    "    sep_days = [15, 16, 17]\n",
    "    oct_days = [1, 2, 3, 4, 5, 6, 7]\n",
    "    if (9 in list(volume_weather['month'].unique())):\n",
    "        for day in sep_days:\n",
    "            volume_weather.loc[((volume_weather['month'] == 9) & (volume_weather['day'] == day)), 'is_festival'] = 1\n",
    "    for day in oct_days:\n",
    "        volume_weather.loc[((volume_weather['month'] == 10) & (volume_weather['day'] == day)), 'is_festival'] = 1\n",
    "        \n",
    "    # Construct 'is_working_day' column\n",
    "    volume_weather['is_working_day'] = np.array([0] * len(volume_weather))\n",
    "    volume_weather.loc[((volume_weather['weekday'] < 5) & (volume_weather['weekday'] > 0)), 'is_working_day'] = 1\n",
    "    volume_weather.loc[volume_weather['is_festival'] == 1, 'is_working_day'] = 0\n",
    "    volume_weather.loc[((volume_weather['month'] == 9) & (volume_weather['day'] == 18)), 'is_working_day'] = 1\n",
    "    volume_weather.loc[((volume_weather['month'] == 10)\n",
    "                        & ((volume_weather['day'] == 8) | (volume_weather['day'] == 9))), 'is_working_day'] = 1\n",
    "\n",
    "    \n",
    "    return volume_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vwgrouped = re_construct_data(vwgrouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vwgrouped.to_csv('vwgrouped_row.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering(vwgrouped):\n",
    "    # Split numerical data\n",
    "    vwgrouped['wind_direction'] = vwgrouped['wind_direction'] // 15 * 15\n",
    "    vwgrouped['precipitation'] = vwgrouped['precipitation'] // 1 * 1\n",
    "    vwgrouped['wind_speed'] = vwgrouped['wind_speed'] // 1 * 1\n",
    "    vwgrouped['temperature'] = vwgrouped['temperature'] // 2 * 2\n",
    "    vwgrouped['rel_humidity'] = vwgrouped['rel_humidity'] // 10 * 10\n",
    "    \n",
    "    # Create dummies\n",
    "    day_list = vwgrouped['day']\n",
    "    hour_list = vwgrouped['hour']\n",
    "    vwgrouped = pd.get_dummies(data=vwgrouped, columns=['weekday', 'day', 'hour', 'rounded_min', 'wind_direction',\n",
    "                                                        'wind_speed', 'temperature', 'rel_humidity', 'precipitation'])\n",
    "    vwgrouped['day'] = day_list\n",
    "    vwgrouped['hour'] = hour_list\n",
    "    \n",
    "    return vwgrouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vwgrouped = feature_engineering(vwgrouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trajectories = pd.read_csv('training/trajectories(table 5)_training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and convert time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_handler_traj(trajectories):\n",
    "\n",
    "    # Initialize 'direction' as 0\n",
    "    trajectories['direction'] = np.array([0] * len(trajectories))\n",
    "    # Drop milesecond and reformat second\n",
    "    trajectories['travel_time'] = (trajectories['travel_time'] // 1 * 1).astype(int)\n",
    "    # Reformat 'starting_time'\n",
    "    trajectories['starting_time'] = trajectories['starting_time'].apply(\n",
    "        lambda t : datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S')).tolist()\n",
    "    # Reformat 'travel_time'\n",
    "    trajectories['travel_time_formatted'] = trajectories['travel_time'].apply(lambda s : datetime.timedelta(seconds=s)).tolist()\n",
    "    # Add 'end_time' \n",
    "    trajectories['end_time'] = (trajectories['starting_time'] + trajectories['travel_time_formatted']).tolist()\n",
    "\n",
    "    # Create time features\n",
    "    e_year_list = trajectories['end_time'].apply(lambda t : t.year).astype(str)\n",
    "    e_month_list = trajectories['end_time'].apply(lambda t : t.month).astype(str)\n",
    "    e_day_list = trajectories['end_time'].apply(lambda t : t.day).astype(str)\n",
    "    e_hour_list = trajectories['end_time'].apply(lambda t : t.hour).astype(str)\n",
    "    e_min_list = trajectories['end_time'].apply(lambda t : t.minute // 20 * 20).astype(str)\n",
    "    slash_list = np.array(['-'] * len(trajectories))\n",
    "\n",
    "    # Create 'window_time'\n",
    "    trajectories['window_time'] = e_year_list + slash_list + e_month_list + slash_list \\\n",
    "            + e_day_list + slash_list + e_hour_list + slash_list + e_min_list\n",
    "        \n",
    "    trajectories['window_time_formatted'] = trajectories['window_time'].apply(\n",
    "            lambda t : datetime.datetime.strptime(t, '%Y-%m-%d-%H-%M'))\n",
    "    \n",
    "    # Shift window_time by 2 hours here\n",
    "    trajectories['window_time_formatted'] = trajectories['window_time_formatted'].apply(\n",
    "            lambda t : (t + datetime.timedelta(hours=2)))\n",
    "\n",
    "    return trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trajectories = time_handler_traj(trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def group_traj(trajectories):\n",
    "    pre_tra = trajectories.groupby(['window_time_formatted', 'tollgate_id', 'direction'])\n",
    "    gp_traj = pre_tra.agg('mean').join(pd.DataFrame(pre_tra.size(), columns=['count']))\n",
    "\n",
    "    gp_traj['window_time_formatted'] = gp_traj.index.get_level_values('window_time_formatted')\n",
    "\n",
    "    gp_traj.rename(columns={'count':'count_traj'}, inplace=True)\n",
    "    \n",
    "    # Put index as column\n",
    "    gp_traj['direction'] = gp_traj.index.get_level_values('direction')\n",
    "    gp_traj['tollgate_id'] = gp_traj.index.get_level_values('tollgate_id')\n",
    "    return gp_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gp_traj = group_traj(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109244\n"
     ]
    }
   ],
   "source": [
    "print sum(gp_traj['count_traj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2336\n"
     ]
    }
   ],
   "source": [
    "print len(test_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_combi(vwgrouped, gp_traj):\n",
    "    \n",
    "    # Split entry and exit data\n",
    "    vwgrouped_in = vwgrouped[vwgrouped['direction'] == 0]\n",
    "    vwgrouped_out = vwgrouped[vwgrouped['direction'] == 1]\n",
    "    \n",
    "    # Create combi table\n",
    "    combi_in = pd.merge(vwgrouped_in, gp_traj, on=['window_time_formatted', 'tollgate_id', 'direction'], how='left')\n",
    "    combi_out = vwgrouped_out.copy()\n",
    "\n",
    "    combi_in = combi_in.fillna(combi_in[:combi_in.shape[0]].mean())\n",
    "    return (combi_in, combi_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(combi_in, combi_out) = create_combi(vwgrouped, gp_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vwgrouped_in = vwgrouped[vwgrouped['direction'] == 0]\n",
    "# vwgrouped_out = vwgrouped[vwgrouped['direction'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combi_in = pd.merge(vwgrouped_in, gp_traj, on=['window_time_formatted', 'tollgate_id', 'direction'], how='left')\n",
    "# combi_out = vwgrouped_out.copy()\n",
    "\n",
    "# combi_in = combi_in.fillna(combi_in[:combi_in.shape[0]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combi_in.to_csv(\"combi_in.csv\")\n",
    "combi_out.to_csv(\"combi_out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_volume = pd.read_csv('testing_phase1/volume(table 6)_test1.csv')\n",
    "test_weather = pd.read_csv('testing_phase1/weather (table 7)_test1.csv')\n",
    "\n",
    "test_trajectories = pd.read_csv('testing_phase1/trajectories(table 5)_test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(test_volume, test_weather) = date_converter(test_volume, test_weather)\n",
    "# Convert 'wind_direction' outlier to 360\n",
    "test_weather.loc[test_weather['wind_direction'] > 360, 'wind_direction'] = 360\n",
    "test_volume_weather = build_merged_tables(test_volume, test_weather)\n",
    "test_vwgrouped = group_vw(test_volume_weather)\n",
    "test_vwgrouped = re_construct_data(test_vwgrouped)\n",
    "test_vwgrouped = feature_engineering(test_vwgrouped)\n",
    "test_trajectories = time_handler_traj(test_trajectories)\n",
    "test_gp_traj = group_traj(test_trajectories)\n",
    "(test_combi_in, test_combi_out) = create_combi(test_vwgrouped, test_gp_traj)\n",
    "test_combi_in.to_csv(\"test_combi_in.csv\")\n",
    "test_combi_out.to_csv(\"test_combi_out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission_sample_volume.csv')\n",
    "\n",
    "sub_weather = pd.read_csv('testing_phase1/weather (table 7)_test1.csv')\n",
    "\n",
    "sub_trajectories = pd.read_csv('testing_phase1/trajectories(table 5)_test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submission_time_converter(df):\n",
    "    df['time_formatted'] = df['time_window'].apply(\n",
    "    lambda t : datetime.datetime.strptime(t.split(',')[0], '[%Y-%m-%d %H:%M:%S'))\n",
    "    df['year'] = df['time_formatted'].apply(lambda t : t.year).astype(int)\n",
    "    df['month'] = df['time_formatted'].apply(lambda t : t.month).astype(int)\n",
    "    df['day'] = df['time_formatted'].apply(lambda t : t.day).astype(int)\n",
    "    df['hour'] = df['time_formatted'].apply(lambda t : t.hour).astype(int)\n",
    "    df['rounded_hour'] = ((df['hour'].astype(int)) // 3 * 3).astype(int)\n",
    "    df['minute'] = df['time_formatted'].apply(lambda t : t.minute).astype(int)\n",
    "    df['rounded_min'] = (df['minute'].astype(int) // 20 * 20).astype(int)\n",
    "    slash = np.array(['-'] * len(df))\n",
    "    df['date_and_rounded_hour'] = df['year'].astype(str) + slash + df['month'].astype(str) \\\n",
    "                                    + slash + df['day'].astype(str) + slash + df['rounded_hour'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_weather['date_and_rounded_hour'] = sub_weather['date'] + np.array(['-'] * len(sub_weather)) + sub_weather['hour'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_volume = submission_time_converter(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_volume_weather = build_merged_tables(sub_volume, sub_weather)\n",
    "sub_vwgrouped = group_vw(sub_volume_weather)\n",
    "sub_vwgrouped = re_construct_data(sub_vwgrouped)\n",
    "sub_vwgrouped = feature_engineering(sub_vwgrouped)\n",
    "sub_trajectories = time_handler_traj(sub_trajectories)\n",
    "sub_gp_traj = group_traj(sub_trajectories)\n",
    "(sub_combi_in, sub_combi_out) = create_combi(sub_vwgrouped, sub_gp_traj)\n",
    "\n",
    "sub_combi_in.to_csv(\"sub_combi_in.csv\")\n",
    "sub_combi_out.to_csv(\"sub_combi_out.csv\")\n",
    "sub_gp_traj.to_csv(\"sub_gp_traj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
