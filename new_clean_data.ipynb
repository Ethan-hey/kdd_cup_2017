{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import datetime\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def volume_time_converter(df, column='time', shift=False):\n",
    "    \n",
    "    # Initialize lists to store splitted information\n",
    "    date_list = []\n",
    "    month_list = []\n",
    "    day_list = []\n",
    "    hour_list = []\n",
    "    minute_list = []\n",
    "    rounded_min_list = []\n",
    "    rounded_hour_list = []\n",
    "    \n",
    "    def split_date(date):\n",
    "        \n",
    "        parts = date.split(\" \")\n",
    "        day_part = parts[0]\n",
    "        clock_part = parts[1]\n",
    "        \n",
    "        day_parts = day_part.split(\"-\")\n",
    "        month_list.append(day_parts[1])\n",
    "        day_list.append(day_parts[2])\n",
    "        \n",
    "        clock_parts = clock_part.split(':')\n",
    "        hour_list.append(clock_parts[0])\n",
    "        minute_list.append(clock_parts[1])\n",
    "        rounded_hour_list.append(int(clock_parts[0]) // 3 * 3)\n",
    "        rounded_min_list.append(int(clock_parts[1]) // 20 * 20)\n",
    "        \n",
    "        date_list.append(day_part)\n",
    "    \n",
    "    # split 'time' feature and store into list\n",
    "    for date in df[column]:\n",
    "        split_date(date)\n",
    "        \n",
    "    # Add arrays into the 'volume' df\n",
    "    df['month'] = np.array(month_list)\n",
    "    df['day'] = np.array(day_list)\n",
    "    df['hour'] = np.array(hour_list)\n",
    "    df['minute'] = np.array(minute_list)\n",
    "    df['date'] = np.array(date_list)\n",
    "    df['rounded_hour'] = np.array(rounded_hour_list)\n",
    "    df['rounded_min'] = np.array(rounded_min_list)\n",
    "    \n",
    "    # Add an colume which combine 'date' and 'rounded_hour'\n",
    "    slash_list = np.array(['-'] * len(df['date']))\n",
    "    df['date_and_rounded_hour'] = df['date'].astype(str) + slash_list + df['rounded_hour'].astype(str)\n",
    "    \n",
    "    df['window_time'] = df['date'].astype(str) + slash_list + df['hour'].astype(str) + slash_list + \\\n",
    "                            df['rounded_min'].astype(str)\n",
    "        \n",
    "    df['window_time_formatted'] = df['window_time'].apply(\n",
    "            lambda t : datetime.datetime.strptime(t, '%Y-%m-%d-%H-%M'))\n",
    "    \n",
    "    # Shift time by 7 days(for submission sample data only)\n",
    "    if shift:\n",
    "        df['window_time_formatted'] = df['window_time_formatted'].apply(\n",
    "            lambda t : (t + datetime.timedelta(days=7)))\n",
    "        df['date'] = df['window_time_formatted'].apply(lambda t : t.date().strftime('%Y-%m-%d'))\n",
    "        df['date_and_rounded_hour'] = df['date'].astype(str) + slash_list + df['rounded_hour'].astype(str)\n",
    "        \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weather_time_converter(df):\n",
    "    \n",
    "    slash_list = np.array(['-'] * len(df))\n",
    "    df['date_and_rounded_hour'] = df['date'] + slash_list + df['hour'].astype(str)\n",
    "    \n",
    "    df['rounded_min'] = np.array([0] * len(df))\n",
    "    \n",
    "    df['window_time'] = df['date'].astype(str) + slash_list + df['hour'].astype(str) + slash_list + \\\n",
    "                            df['rounded_min'].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traj_time_converter(df):\n",
    "    \n",
    "    # Initialize 'direction' as 0\n",
    "    df['direction'] = np.array([0] * len(df))\n",
    "    \n",
    "    # Drop milesecond and reformat second\n",
    "    df['travel_time'] = (df['travel_time'] // 1 * 1).astype(int)\n",
    "    \n",
    "    # Reformat 'starting_time'\n",
    "    df['starting_time_formatted'] = df['starting_time'].apply(\n",
    "        lambda t : datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    # Reformat 'travel_time'\n",
    "    df['travel_time_formatted'] = df['travel_time'].apply(lambda s : datetime.timedelta(seconds=s))\n",
    "    \n",
    "    # Add 'end_time' \n",
    "    df['end_time_formatted'] = (df['starting_time_formatted'] + df['travel_time_formatted'])\n",
    "\n",
    "    # Create time features\n",
    "    year_list = df['end_time_formatted'].apply(lambda t : t.year).astype(str)\n",
    "    month_list = df['end_time_formatted'].apply(lambda t : t.month).astype(str)\n",
    "    day_list = df['end_time_formatted'].apply(lambda t : t.day).astype(str)\n",
    "    hour_list = df['end_time_formatted'].apply(lambda t : t.hour).astype(str)\n",
    "    min_list = df['end_time_formatted'].apply(lambda t : t.minute).astype(str)\n",
    "    rounded_hour_list = hour_list.astype(int).apply(lambda t : t // 3 * 3).astype(str)\n",
    "    rounded_min_list = min_list.astype(int).apply(lambda t : t // 20 * 20).astype(str)\n",
    "    slash_list = np.array(['-'] * len(df))\n",
    "    \n",
    "    df['year'] = year_list\n",
    "    df['month'] = month_list\n",
    "    df['day'] = day_list\n",
    "    df['hour'] = hour_list\n",
    "    df['min'] = min_list\n",
    "    df['rounded_hour'] = rounded_hour_list\n",
    "    df['rounded_min'] = rounded_min_list\n",
    "    \n",
    "\n",
    "    # Create 'window_time'\n",
    "    df['window_time'] = year_list + slash_list + month_list + slash_list \\\n",
    "            + day_list + slash_list + hour_list + slash_list + rounded_min_list\n",
    "        \n",
    "    df['window_time_formatted'] = df['window_time'].apply(\n",
    "            lambda t : datetime.datetime.strptime(t, '%Y-%m-%d-%H-%M'))\n",
    "    \n",
    "    df['date_and_rounded_hour'] = year_list + slash_list + month_list + slash_list \\\n",
    "            + day_list + slash_list + rounded_hour_list\n",
    "    \n",
    "    # Shift window_time by 2 hours here(as only last 2 hours data are provided in test set)\n",
    "    df['window_time_formatted'] = df['window_time_formatted'].apply(\n",
    "            lambda t : (t + datetime.timedelta(hours=2)))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and group data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge volume and weather \n",
    "def group_vol_wea(volume, weather):\n",
    "    \n",
    "    df = pd.merge(volume, weather, on='date_and_rounded_hour', suffixes=('', '_y'), how='left')\n",
    "    \n",
    "    df = df.groupby(['window_time_formatted', 'tollgate_id', 'direction'])\n",
    "    \n",
    "    df_gp = df.agg('mean').join(pd.DataFrame(df.size(), columns=['count']))\n",
    "    \n",
    "    # Put index as column\n",
    "    df_gp['direction'] = df_gp.index.get_level_values('direction')\n",
    "    df_gp['tollgate_id'] = df_gp.index.get_level_values('tollgate_id')\n",
    "    df_gp['window_time_formatted'] = df_gp.index.get_level_values('window_time_formatted')\n",
    "    \n",
    "    return df_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_traj(df):\n",
    "    \n",
    "    df = df.groupby(['window_time_formatted', 'tollgate_id', 'direction'])\n",
    "    df_gp = df.agg('mean').join(pd.DataFrame(df.size(), columns=['count']))\n",
    "    \n",
    "    # Put index as column\n",
    "    df_gp['direction'] = df_gp.index.get_level_values('direction')\n",
    "    df_gp['tollgate_id'] = df_gp.index.get_level_values('tollgate_id')\n",
    "    df_gp['window_time_formatted'] = df_gp.index.get_level_values('window_time_formatted')\n",
    "    \n",
    "    return df_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge volume_weather and trajectories\n",
    "def merge_vwt(vw_gp, t_gp):\n",
    "    \n",
    "    vwt = pd.merge(vw_gp, t_gp, on=['window_time_formatted', 'tollgate_id', 'direction'], suffixes=('', '_y'), how='left')\n",
    "    \n",
    "    # Drop useless columns\n",
    "    drop_columns = ['vehicle_id', 'vehicle_model', 'vehicle_type', 'hour_y', 'rounded_min_y', 'has_etc']\n",
    "    for col in drop_columns:\n",
    "        if col in vwt.columns:\n",
    "            vwt.drop([col], axis=1, inplace=True)\n",
    "            \n",
    "    vwt.rename(columns={'count_y':'traj_count'}, inplace=True)\n",
    "    \n",
    "    return vwt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add features: 'weekday', 'is_festival', 'is_working_day'\n",
    "def add_features(vwt):\n",
    "    \n",
    "    vwt['month'] = vwt['window_time_formatted'].apply(lambda t : t.month)\n",
    "    vwt['day'] = vwt['window_time_formatted'].apply(lambda t : t.day)\n",
    "    \n",
    "    # Create 'weekday' column in DateFrame(0 stands for Sunday; 1 stands for Monday and 2 stands for Tuesday, etc...)\n",
    "    if (9 in list(vwt['month'].unique())):\n",
    "        sept = vwt[vwt['month'] == 9]\n",
    "        weekday1 = ((sept['day'] + 3) % 7).values\n",
    "        octo = vwt[vwt['month'] == 10]\n",
    "        weekday2 = ((octo['day'] + 5) % 7).values\n",
    "        vwt['weekday'] = np.append(weekday1, weekday2)\n",
    "    else:\n",
    "        weekday2 = ((vwt['day'] + 5) % 7).values\n",
    "        vwt['weekday'] = np.array(weekday2)\n",
    "        \n",
    "    # Create 'is_festival' column\n",
    "    vwt['is_festival'] = np.array([0] * len(vwt))\n",
    "    sep_days = [15, 16, 17, 30]\n",
    "    oct_days = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    if (9 in list(vwt['month'].unique())):\n",
    "        for day in sep_days:\n",
    "            vwt.loc[((vwt['month'] == 9) & (vwt['day'] == day)), 'is_festival'] = 1\n",
    "    for day in oct_days:\n",
    "        vwt.loc[((vwt['month'] == 10) & (vwt['day'] == day)), 'is_festival'] = 1\n",
    "        \n",
    "    # Construct 'is_working_day' column\n",
    "    vwt['is_working_day'] = np.array([0] * len(vwt))\n",
    "    vwt.loc[((vwt['weekday'] < 5) & (vwt['weekday'] > 0)), 'is_working_day'] = 1\n",
    "    vwt.loc[vwt['is_festival'] == 1, 'is_working_day'] = 0\n",
    "    vwt.loc[((vwt['month'] == 9) & (vwt['day'] == 18)), 'is_working_day'] = 1\n",
    "    vwt.loc[((vwt['month'] == 10)\n",
    "                        & ((vwt['day'] == 8) | (vwt['day'] == 9))), 'is_working_day'] = 1\n",
    "    \n",
    "    return vwt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### more needs to be done. 'travel_time' nas are not supposed to filled with meadian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_na(vwt):\n",
    "    \n",
    "#     weather_features = ['pressure', 'sea_pressure', 'wind_direction', 'wind_speed', 'temperature', 'rel_humidity', 'precipitation']\n",
    "#     for fea in weather_features:\n",
    "#         vwt[fea] = vwt.groupby(\"rounded_hour\").transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "    vwt = vwt.fillna(vwt[:vwt.shape[0]].mean())\n",
    "    \n",
    "#     vwt_out = vwt[vwt['direction'] == 1]\n",
    "#     vwt_in = vwt[vwt['direction'] == 0]\n",
    "    \n",
    "#     vwt_out.drop(['travel_time', 'traj_count'], axis=1, inplace=True)\n",
    "\n",
    "    return vwt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dummy(vwt):\n",
    "    \n",
    "    vwt['hour'] = vwt['window_time_formatted'].apply(lambda t : t.hour)\n",
    "    \n",
    "    # Split numerical data\n",
    "    vwt['wind_direction'] = vwt['wind_direction'] // 15 * 15\n",
    "    vwt['precipitation'] = vwt['precipitation'] // 1 * 1\n",
    "    vwt['wind_speed'] = vwt['wind_speed'] // 1 * 1\n",
    "    vwt['temperature'] = vwt['temperature'] // 2 * 2\n",
    "    vwt['rel_humidity'] = vwt['rel_humidity'] // 10 * 10\n",
    "    \n",
    "    day_list = vwt['day']\n",
    "    hour_list = vwt['hour']\n",
    "    weekday_list = vwt['weekday']\n",
    "    \n",
    "    # Create dummies\n",
    "    vwt = pd.get_dummies(data=vwt, columns=['weekday', 'hour', 'rounded_min', 'wind_direction',\n",
    "                                                        'wind_speed', 'temperature', 'rel_humidity', 'precipitation'])\n",
    "    vwt['day'] = day_list\n",
    "    vwt['hour'] = hour_list\n",
    "    vwt['weekday'] = weekday_list\n",
    "    \n",
    "    return vwt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature 'history average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_his_ave(df):\n",
    "\n",
    "    df = df[df['is_festival'] == 0]\n",
    "    \n",
    "    df['time'] = df['window_time_formatted'].apply(lambda t : t.time())\n",
    "    df_his = df.groupby(['time', 'tollgate_id', 'direction', 'weekday']).agg('mean')\n",
    "    df_his.rename(columns={'count':'his_ave'}, inplace=True)\n",
    "    \n",
    "    df_his['direction'] = df_his.index.get_level_values('direction')\n",
    "    df_his['tollgate_id'] = df_his.index.get_level_values('tollgate_id')\n",
    "    df_his['time'] = df_his.index.get_level_values('time')\n",
    "    df_his['weekday'] = df_his.index.get_level_values('weekday')\n",
    "\n",
    "    \n",
    "    return df_his[['time', 'tollgate_id', 'direction', 'his_ave', 'weekday']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add feature 'his_ave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_his_ave(df, vwt_his):\n",
    "    \n",
    "    df['time'] = df['window_time_formatted'].apply(lambda t : t.time())\n",
    "    df = pd.merge(df, vwt_his, on=['time', 'tollgate_id', 'direction', 'weekday'], suffixes=('', '_y'), how='left' )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links = pd.read_csv('training/links (table 3).csv')\n",
    "routes = pd.read_csv('training/routes (table 4).csv')\n",
    "trajectories = pd.read_csv('training/trajectories(table 5)_training.csv')\n",
    "volume = pd.read_csv('training/volume(table 6)_training.csv')\n",
    "weather = pd.read_csv('training/weather (table 7)_training.csv')\n",
    "\n",
    "volume_late = pd.read_csv('dataSet_phase2/volume(table 6)_training2.csv')\n",
    "trajectories_late = pd.read_csv('dataSet_phase2/trajectories(table_5)_training2.csv')\n",
    "weather_late = pd.read_csv('dataSet_phase2/weather (table 7)_2.csv')\n",
    "\n",
    "volume_late.rename(columns={'tollgate':'tollgate_id', 'date_time':'time',\n",
    "                            'is_etc':'has_etc', 'model':'vehicle_model'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volume = pd.concat([volume, volume_late])\n",
    "weather = pd.concat([weather, weather_late])\n",
    "trajectories = pd.concat([trajectories, trajectories_late])\n",
    "\n",
    "# Convert 'wind_direction' outlier to 360\n",
    "weather.loc[weather['wind_direction'] > 360, 'wind_direction'] = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THINKPAD\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "v = volume.copy()\n",
    "t = trajectories.copy()\n",
    "w = weather.copy()\n",
    "\n",
    "v = volume_time_converter(v)\n",
    "t = traj_time_converter(t)\n",
    "w = weather_time_converter(w)\n",
    "\n",
    "vw_gp = group_vol_wea(v, w)\n",
    "t_gp = group_traj(t)\n",
    "vwt = merge_vwt(vw_gp, t_gp)\n",
    "\n",
    "vwt = add_features(vwt)\n",
    "vwt = fill_na(vwt)\n",
    "vwt = create_dummy(vwt)\n",
    "vwt_his = create_his_ave(vwt)\n",
    "vwt = add_his_ave(vwt, vwt_his)\n",
    "vwt = vwt[vwt['hour'].isin([8, 9, 17, 18])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_volume = pd.read_csv('submission_sample_volume.csv')\n",
    "\n",
    "sub_weather = pd.read_csv('dataSet_phase2/weather (table 7)_2.csv')\n",
    "\n",
    "sub_trajectories = pd.read_csv('dataSet_phase2/trajectories(table 5)_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_volume['time'] = sub_volume['time_window'].apply(\n",
    "            lambda t : t.split(',')[0].split('[')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_v = sub_volume.copy()\n",
    "sub_w = sub_weather.copy()\n",
    "sub_t = sub_trajectories.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_v = volume_time_converter(sub_v, column='time', shift=True)\n",
    "sub_v.rename(columns={'tollgate':'tollgate_id'}, inplace=True)\n",
    "sub_t = traj_time_converter(sub_t)\n",
    "sub_w = weather_time_converter(sub_w)\n",
    "sub_vw_gp = group_vol_wea(sub_v, sub_w)\n",
    "sub_t_gp = group_traj(sub_t)\n",
    "sub_vwt = merge_vwt(sub_vw_gp, sub_t_gp)\n",
    "sub_vwt = add_features(sub_vwt)\n",
    "sub_vwt = fill_na(sub_vwt)\n",
    "sub_vwt = create_dummy(sub_vwt)\n",
    "sub_vwt = add_his_ave(sub_vwt, vwt_his)\n",
    "sub_vwt = sub_vwt[sub_vwt['hour'].isin([8, 9, 17, 18])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vwt.to_csv('train_vwt.csv')\n",
    "# sub_vwt.to_csv('sub_vwt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = vwt.copy()\n",
    "vwt_copy = vwt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['traj_count', 'travel_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_mask = df[features[0]].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[~na_mask][['time', 'tollgate_id', 'direction', features[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.groupby(['time', 'tollgate_id', 'direction']).agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['time'] = df.index.get_level_values('time')\n",
    "df['tollgate_id'] = df.index.get_level_values('tollgate_id')\n",
    "df['direction'] = df.index.get_level_values('direction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vwt_copy = pd.merge(vwt_copy, df, on=['time', 'tollgate_id', 'direction', features[0]], suffixes=('', '_y'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vwt_copy[vwt_copy['direction'] == 0].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sub_vwtc[sub_vwtc['direction'] == 0].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vv = vwt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vv['date'] = vwt['window_time_formatted'].apply(lambda t : t.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
